{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPKgFSsSDa7xY3q/nW7MfHr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rithikkulkarni/ALDA-Course-Project/blob/main/finbert_labeling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initial preprocessing code"
      ],
      "metadata": {
        "id": "syE32BN9Qnfz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qpLO2md-QiUc"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/rithikkulkarni/ALDA-Course-Project/refs/heads/main/datasets/stock_tweets.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "1ldhJcnmQpdz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "WbGrNa3HQqkq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "id": "lFLUhcwDQr7N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "pipe = pipeline(\"text-classification\", model=\"ProsusAI/finbert\", device=\"cuda\")"
      ],
      "metadata": {
        "id": "XtppJcKIQtLN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Function for using FinBERT to label our data for supervised learning\n",
        "def label_data(tweet_text):\n",
        "  temp = pipe(tweet_text)\n",
        "  if 'positive' in str(temp[0]):\n",
        "    return 'positive'\n",
        "  elif 'negative' in str(temp[0]):\n",
        "    return 'negative'\n",
        "  else:\n",
        "    return 'neutral'\n",
        "\n",
        "### Function for using FinBERT that should be faster because it process multiple tweets in parallel\n",
        "def label_data_batch(tweet_texts, batch_size=32):\n",
        "    results = pipe(tweet_texts, batch_size=batch_size)\n",
        "    labels = []\n",
        "    for res in results:\n",
        "        if 'positive' in str(res):\n",
        "            labels.append('positive')\n",
        "        elif 'negative' in str(res):\n",
        "            labels.append('negative')\n",
        "        else:\n",
        "            labels.append('neutral')\n",
        "    return labels"
      ],
      "metadata": {
        "id": "mQf7i1FeQvB4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import numpy as np\n",
        "\n",
        "# batch_size = 32  # Adjust based on memory and speed\n",
        "# tweet_batches = np.array_split(df['Tweet'].to_numpy(), len(df) // batch_size + 1)\n",
        "# label_batches = [label_data_batch(batch.tolist()) for batch in tweet_batches]\n",
        "\n",
        "# # Flatten the list of label batches\n",
        "# df['label'] = np.concatenate(label_batches)\n",
        "\n",
        "import torch\n",
        "from datasets import Dataset\n",
        "\n",
        "# Ensure GPU is enabled\n",
        "device = 0 if torch.cuda.is_available() else -1\n",
        "pipe = pipeline(\"text-classification\", model=\"ProsusAI/finbert\", device=device)\n",
        "\n",
        "# Convert DataFrame to Hugging Face Dataset\n",
        "dataset = Dataset.from_pandas(df[['Tweet']])  # Keep only relevant column\n",
        "\n",
        "# Define a function to process tweets\n",
        "def label_data_batch(batch):\n",
        "    results = pipe(batch['Tweet'], batch_size=32)  # Adjust batch size\n",
        "    return {'label': [res['label'].lower() for res in results]}  # Convert to lowercase\n",
        "\n",
        "# Apply the function to the dataset\n",
        "labeled_dataset = dataset.map(label_data_batch, batched=True)\n",
        "\n",
        "# Convert back to DataFrame\n",
        "df['label'] = labeled_dataset['label']"
      ],
      "metadata": {
        "id": "S4D5xM14Qwa7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "rdbqkY48QxhC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.rename(columns={'label': 'Label'}, inplace=True)\n",
        "df.info()"
      ],
      "metadata": {
        "id": "KNJli__lQyX-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.Label.value_counts()"
      ],
      "metadata": {
        "id": "Zbhy6NEiQzft"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### To be used for stock price\n",
        "\n",
        "import yfinance as yf\n",
        "\n",
        "ticker = yf.Ticker(\"AAPL\")\n",
        "hist = ticker.history(start=\"2024-02-05\", end=\"2024-02-12\")\n",
        "print(hist)"
      ],
      "metadata": {
        "id": "RTScwgYjQ0OD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}