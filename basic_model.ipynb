{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier  # Example classifier\n",
    "from sklearn.linear_model import LogisticRegression # Alternative classifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration ---\n",
    "CSV_FILE_PATH = 'datasets/labeled_stock_tweets_with_historical_prices.csv'  # <--- CHANGE THIS to your CSV file path\n",
    "TARGET_COLUMN = 'stock_label'\n",
    "# TEXT_FEATURE = 'Cleaned_Tweet'\n",
    "NUMERICAL_FEATURES = ['one_day_price', 'two_day_price', 'three_day_price', 'historical_price'\n",
    "                      , 'Label'\n",
    "                      ]\n",
    "# CATEGORICAL_FEATURES = ['Stock Name'] # Assuming 'Stock Name' is the primary identifier\n",
    "# You could add 'Company Name' here too, but it might be redundant if Stock Name is unique\n",
    "# CATEGORICAL_FEATURES = ['Stock Name', 'Company Name']\n",
    "\n",
    "TEST_SIZE = 0.2  # 20% of data for testing\n",
    "RANDOM_STATE = 42 # For reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded data. Shape: (20935, 11)\n",
      "\n",
      "Sample data:\n",
      "         Date                                              Tweet Stock Name  \\\n",
      "0  2022-07-28  @TSM_Albralelie I am sure you'll find somethin...        TSM   \n",
      "1  2022-04-14            The factories are firing back on - $NIO        NIO   \n",
      "2  2022-05-31  watchlist for tomorrow: | $SPX | $CRM | $KHC |...        CRM   \n",
      "3  2022-08-12  Very interesting data from Jefferies showing C...        AMD   \n",
      "4  2022-07-22  Argus analyst Bill Selesky lowered the price t...       TSLA   \n",
      "\n",
      "                                        Company Name  Label  \\\n",
      "0  Taiwan Semiconductor Manufacturing Company Lim...      1   \n",
      "1                                           NIO Inc.     -1   \n",
      "2                                   Salesforce, Inc.      0   \n",
      "3                       Advanced Micro Devices, Inc.      1   \n",
      "4                                        Tesla, Inc.      0   \n",
      "\n",
      "                                       Cleaned_Tweet  stock_label  \\\n",
      "0  user sure youll find someth brother your liter...            0   \n",
      "1                              factori fire back nio           -1   \n",
      "2           watchlist tomorrow spx crm khc codx mara            1   \n",
      "3  interest data jefferi show cpu gpu instanc sha...            0   \n",
      "4  argu analyst bill seleski lower price target t...            0   \n",
      "\n",
      "   one_day_price  two_day_price  three_day_price  historical_price  \n",
      "0          83.48          80.42            82.22             81.35  \n",
      "1          20.42          19.46            19.70             21.19  \n",
      "2         164.18         161.56           158.76            159.60  \n",
      "3          98.12          99.05            95.54             98.12  \n",
      "4         271.71         247.50           245.53            243.95  \n",
      "\n",
      "Target variable distribution:\n",
      "stock_label\n",
      " 0    0.388297\n",
      " 1    0.312634\n",
      "-1    0.299069\n",
      "Name: proportion, dtype: float64\n",
      "stock_label\n",
      " 0    8129\n",
      " 1    6545\n",
      "-1    6261\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    df = pd.read_csv(CSV_FILE_PATH)\n",
    "    df = df.sample(frac=1, random_state=RANDOM_STATE).reset_index(drop=True)  # Shuffle the DataFrame\n",
    "    print(f\"Successfully loaded data. Shape: {df.shape}\")\n",
    "    print(\"\\nSample data:\")\n",
    "    print(df.head())\n",
    "    print(f\"\\nTarget variable distribution:\\n{df[TARGET_COLUMN].value_counts(normalize=True)}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: File not found at {CSV_FILE_PATH}\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"Error loading data: {e}\")\n",
    "    exit()\n",
    "print(df['stock_label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training set size: 16748\n",
      "Test set size: 4187\n"
     ]
    }
   ],
   "source": [
    "# --- 2. Define Features (X) and Target (y) ---\n",
    "X = df[NUMERICAL_FEATURES]\n",
    "y = df[TARGET_COLUMN]\n",
    "\n",
    "# --- 3. Split Data ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=TEST_SIZE,\n",
    "    random_state=RANDOM_STATE,\n",
    "    stratify=y # Important for classification, especially if classes are imbalanced\n",
    ")\n",
    "print(f\"\\nTraining set size: {X_train.shape[0]}\")\n",
    "print(f\"Test set size: {X_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training the model...\n",
      "Model training complete.\n",
      "\n",
      "Making predictions on the test set...\n",
      "\n",
      "--- Model Evaluation ---\n",
      "Accuracy: 0.9690\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Down (-1)       0.97      0.96      0.97      1252\n",
      " Neutral (0)       0.97      0.97      0.97      1626\n",
      "      Up (1)       0.97      0.97      0.97      1309\n",
      "\n",
      "    accuracy                           0.97      4187\n",
      "   macro avg       0.97      0.97      0.97      4187\n",
      "weighted avg       0.97      0.97      0.97      4187\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "                Predicted Down  Predicted Neutral  Predicted Up\n",
      "Actual Down               1204                 30            18\n",
      "Actual Neutral              23               1579            24\n",
      "Actual Up                   15                 20          1274\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- 5. Choose and Define the Model ---\n",
    "# Using RandomForestClassifier as an example. It often works well with mixed data.\n",
    "# You can adjust n_estimators, max_depth, etc., or try other models.\n",
    "# class_weight='balanced' can help if your classes (-1, 0, 1) are imbalanced.\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=RANDOM_STATE, class_weight='balanced', n_jobs=-1)\n",
    "\n",
    "# Alternative: Logistic Regression (often faster, good baseline)\n",
    "# model = LogisticRegression(multi_class='ovr', solver='liblinear', class_weight='balanced', random_state=RANDOM_STATE)\n",
    "\n",
    "print(\"\\nTraining the model...\")\n",
    "model.fit(X_train, y_train)\n",
    "print(\"Model training complete.\")\n",
    "\n",
    "# --- 7. Make Predictions ---\n",
    "print(\"\\nMaking predictions on the test set...\")\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# --- 8. Evaluate the Model ---\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\n--- Model Evaluation ---\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "# Use labels=[-1, 0, 1] to ensure all classes are shown even if one is missing in predictions\n",
    "# zero_division=0 handles cases where precision/recall might be zero for a class\n",
    "print(classification_report(y_test, y_pred, labels=[-1, 0, 1], target_names=['Down (-1)', 'Neutral (0)', 'Up (1)'], zero_division=0))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "# Rows: Actual, Columns: Predicted\n",
    "cm = confusion_matrix(y_test, y_pred, labels=[-1, 0, 1])\n",
    "print(pd.DataFrame(cm, index=['Actual Down', 'Actual Neutral', 'Actual Up'],\n",
    "                   columns=['Predicted Down', 'Predicted Neutral', 'Predicted Up']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
