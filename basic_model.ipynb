{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rithikkulkarni/ALDA-Course-Project/blob/main/basic_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "zVIm1P5n1Ila"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Configuration ---\n",
        "CSV_FILE_PATH = 'https://raw.githubusercontent.com/rithikkulkarni/ALDA-Course-Project/refs/heads/main/datasets/filtered_stocks_test.csv'\n",
        "TARGET_COLUMN = 'stock_performance'\n",
        "# TEXT_FEATURE = 'Cleaned_Tweet'\n",
        "NUMERICAL_FEATURES = ['one_day_price', 'two_day_price', 'three_day_price', 'historical_price'\n",
        "                        #  , 'sentiment'\n",
        "                      ]\n",
        "\n",
        "TEST_SIZE = 0.2  # 20% of data for testing\n",
        "RANDOM_STATE = 42 # For reproducibility"
      ],
      "metadata": {
        "id": "Z1l1DluH1RxP"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(CSV_FILE_PATH)\n",
        "df = df.sample(frac=1, random_state=RANDOM_STATE).reset_index(drop=True)  # Shuffle the DataFrame\n",
        "print(f\"Successfully loaded data. Shape: {df.shape}\")\n",
        "print(\"\\nSample data:\")\n",
        "df.head(1)\n",
        "\n",
        "\n",
        "print(df['stock_performance'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "klGq8kku1UDj",
        "outputId": "22a47b12-ee80-47ee-bdf0-5efeaf6b1ae9"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully loaded data. Shape: (4184, 10)\n",
            "\n",
            "Sample data:\n",
            "stock_performance\n",
            "-1    2171\n",
            " 1    2013\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This cell gets an equal sample from each label, so we end up with a valid accuracy that isn't inflated from too many of one label\n",
        "\n",
        "# Find the minimum class count across the classes\n",
        "min_count = df['stock_performance'].value_counts().min()\n",
        "print(f\"min_count = {min_count}\")\n",
        "\n",
        "# Create a balanced dataframe by sampling min_count instances from each group\n",
        "df = df.groupby('stock_performance').sample(n=min_count, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# Sanity check for class balance\n",
        "print(df['stock_performance'].value_counts())"
      ],
      "metadata": {
        "id": "rU-fODgXOsB2",
        "outputId": "e885610c-b90d-402b-9971-2447b285fd80",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "min_count = 2013\n",
            "stock_performance\n",
            "-1    2013\n",
            " 1    2013\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import xgboost as xgb\n",
        "\n",
        "# --- 1. Load and Prepare Data (assuming previous cells have done this) ---\n",
        "# For example:\n",
        "# df = pd.read_csv(CSV_FILE_PATH)\n",
        "# ... any necessary preprocessing ...\n",
        "\n",
        "# --- 2. Define Features (X) and Target (y) ---\n",
        "X = df[NUMERICAL_FEATURES]\n",
        "y = df['pct_change']  # Target is now 'pct_change'\n",
        "\n",
        "# --- 3. Split Data ---\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=TEST_SIZE,\n",
        "    random_state=RANDOM_STATE\n",
        ")\n",
        "\n",
        "# --- 4. Hyperparameter Tuning with XGBoost using GridSearchCV ---\n",
        "# Define a parameter grid to explore\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "    'subsample': [0.8, 1.0]\n",
        "}\n",
        "\n",
        "# Initialize GridSearchCV with XGBRegressor\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=xgb.XGBRegressor(random_state=RANDOM_STATE),\n",
        "    param_grid=param_grid,\n",
        "    scoring='r2',  # Optimizing for RÂ² score\n",
        "    cv=5,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "print(\"\\nStarting grid search for XGBoost hyperparameter tuning...\")\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(\"\\nBest parameters found:\")\n",
        "print(grid_search.best_params_)\n",
        "\n",
        "# Use the best estimator from the grid search\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# --- 5. Make Predictions with the Best XGBoost Model ---\n",
        "print(\"\\nMaking predictions on the test set using the best XGBoost model...\")\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "# --- 6. Evaluate the Model ---\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = mse**0.5\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"\\n--- Model Evaluation ---\")\n",
        "print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
        "print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
        "print(f\"R-squared (R2): {r2:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5OsJvJwcje4N",
        "outputId": "6ac4d245-5efe-4fea-81ed-6ca9502af395"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting grid search for XGBoost hyperparameter tuning...\n",
            "\n",
            "Best parameters found:\n",
            "{'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 100, 'subsample': 0.8}\n",
            "\n",
            "Making predictions on the test set using the best XGBoost model...\n",
            "\n",
            "--- Model Evaluation ---\n",
            "Mean Squared Error (MSE): 9.7094\n",
            "Root Mean Squared Error (RMSE): 3.1160\n",
            "R-squared (R2): -0.0065\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 2. Define Features (X) and Target (y) ---\n",
        "X = df[NUMERICAL_FEATURES]\n",
        "y = df[TARGET_COLUMN]\n",
        "\n",
        "# --- 3. Split Data ---\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=TEST_SIZE,\n",
        "    random_state=RANDOM_STATE,\n",
        "    stratify=y\n",
        ")\n",
        "print(f\"\\nTraining set size: {X_train.shape[0]}\")\n",
        "print(f\"Test set size: {X_test.shape[0]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pah24PaH1dIO",
        "outputId": "dab3207b-6e4a-405e-f81c-dcb38f53c252"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training set size: 3220\n",
            "Test set size: 806\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 5. Choose and Define the Model ---\n",
        "# Using RandomForestClassifier as an example. It often works well with mixed data.\n",
        "# You can adjust n_estimators, max_depth, etc., or try other models.\n",
        "# class_weight='balanced' can help if your classes (-1, 0, 1) are imbalanced.\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=RANDOM_STATE, class_weight='balanced', n_jobs=-1)\n",
        "\n",
        "# Alternative: Logistic Regression (often faster, good baseline)\n",
        "model = LogisticRegression(multi_class='ovr', solver='liblinear', class_weight='balanced', random_state=RANDOM_STATE)\n",
        "\n",
        "print(\"\\nTraining the model...\")\n",
        "model.fit(X_train, y_train)\n",
        "print(\"Model training complete.\")\n",
        "\n",
        "# --- 7. Make Predictions ---\n",
        "print(\"\\nMaking predictions on the test set...\")\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# --- 8. Evaluate the Model ---\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"\\n--- Model Evaluation ---\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "# Use labels=[-1, 0, 1] to ensure all classes are shown even if one is missing in predictions\n",
        "# zero_division=0 handles cases where precision/recall might be zero for a class\n",
        "print(classification_report(y_test, y_pred, labels=[-1, 0, 1], target_names=['Down (-1)', 'Neutral (0)', 'Up (1)'], zero_division=0))\n",
        "\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "# Rows: Actual, Columns: Predicted\n",
        "cm = confusion_matrix(y_test, y_pred, labels=[-1, 0, 1])\n",
        "print(pd.DataFrame(cm, index=['Actual Down', 'Actual Neutral', 'Actual Up'],\n",
        "                   columns=['Predicted Down', 'Predicted Neutral', 'Predicted Up']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GtKQwMr31dvo",
        "outputId": "aa0c6447-c2fb-466b-f820-bc26272fb7d8"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training the model...\n",
            "Model training complete.\n",
            "\n",
            "Making predictions on the test set...\n",
            "\n",
            "--- Model Evaluation ---\n",
            "Accuracy: 0.5000\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Down (-1)       0.50      0.58      0.54       403\n",
            " Neutral (0)       0.00      0.00      0.00         0\n",
            "      Up (1)       0.50      0.42      0.46       403\n",
            "\n",
            "    accuracy                           0.50       806\n",
            "   macro avg       0.33      0.33      0.33       806\n",
            "weighted avg       0.50      0.50      0.50       806\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "                Predicted Down  Predicted Neutral  Predicted Up\n",
            "Actual Down                234                  0           169\n",
            "Actual Neutral               0                  0             0\n",
            "Actual Up                  234                  0           169\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: i now need a cell to predict a column called pct_change instead of stock_performance. the issue is that pct_change is a float instead of just being -1 0 or 1, so im not sure what model to use\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor  # Use a regressor for float target\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# ... (Previous code remains the same)\n",
        "\n",
        "# --- 2. Define Features (X) and Target (y) ---\n",
        "X = df[NUMERICAL_FEATURES]\n",
        "y = df['pct_change']  # Target is now 'pct_change'\n",
        "\n",
        "# --- 3. Split Data ---\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=TEST_SIZE,\n",
        "    random_state=RANDOM_STATE\n",
        "    # No need for stratify with regression\n",
        ")\n",
        "\n",
        "# --- 5. Choose and Define the Model ---\n",
        "model = RandomForestRegressor(n_estimators=100, random_state=RANDOM_STATE, n_jobs=-1)\n",
        "\n",
        "print(\"\\nTraining the model...\")\n",
        "model.fit(X_train, y_train)\n",
        "print(\"Model training complete.\")\n",
        "\n",
        "# --- 7. Make Predictions ---\n",
        "print(\"\\nMaking predictions on the test set...\")\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# --- 8. Evaluate the Model ---\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = mse**0.5\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"\\n--- Model Evaluation ---\")\n",
        "print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
        "print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
        "print(f\"R-squared (R2): {r2:.4f}\")\n"
      ],
      "metadata": {
        "id": "av76bSKciQvo",
        "outputId": "21aba7b8-6ac3-4d33-a3ab-d072bf789b22",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training the model...\n",
            "Model training complete.\n",
            "\n",
            "Making predictions on the test set...\n",
            "\n",
            "--- Model Evaluation ---\n",
            "Mean Squared Error (MSE): 10.8778\n",
            "Root Mean Squared Error (RMSE): 3.2981\n",
            "R-squared (R2): -0.1276\n"
          ]
        }
      ]
    }
  ]
}